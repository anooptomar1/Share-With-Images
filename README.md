# Share-With-Images
AR iOS app for a vision-based tangible interface

Requirements

 - Tech:
   - Device with iOS 11.3 or greater
   - XCode 9.3 or greater to build the code (with ARKit)
  
 - Knowledge: Ability to read, understand and/or write iOS app code. Don't worry if you're a novice or outright beginner. I've used and adapted apple tutorial code myself to write this app. Go through the following tutorials and links in the given order and you should be able to understand my code
   - [Get started with Swift](https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/index.html#//apple_ref/doc/uid/TP40014097)
   - [Get started with iOS apps](https://developer.apple.com/library/content/referencelibrary/GettingStarted/DevelopiOSAppsSwift/index.html#//apple_ref/doc/uid/TP40015214-CH2-SW1): This gives a good intro to XCode as well
   - [Build your first AR Experience](https://developer.apple.com/documentation/arkit/building_your_first_ar_experience)
   - [Image recognition using ARKit and other related examples](https://developer.apple.com/documentation/arkit/recognizing_images_in_an_ar_experience)
   There are swift playgrounds in most of these links. Download them and try playing around with the code.
   
Expected Future Work:

 - Work on the UI (the look and feel) (Dont want it to resemble the tutorial app too much :))
 - Work on an AI component (See issue #16).
 - The big one: extend to 3D objects and not just images as inputs. Maybe ARKit already has an object detection function implemented somewhere?
 - Unknown ...
 - Extend to android and desktop? (I've used ARKit in this one. Maybe there could be an equivalent version that uses some open source AR SDK?)
   
